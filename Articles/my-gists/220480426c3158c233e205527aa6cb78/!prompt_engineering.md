# プロンプトエンジニアリングについて

## プロンプトエンジニアリング

プロンプトエンジニアリングは、OpenAIが開発した自然言語処理モデルであるGPT（Generative Pre-trained Transformer）を使用して、特定のタスクや目的に合わせたテキスト生成を行う技術の一種です。以下にプロンプトエンジニアリングに関する詳細を示します。

### 1. GPTモデル

- **GPTモデル**: GPTは、大規模なテキストデータセットで事前トレーニングされた自然言語処理モデルです。GPT-3などのバージョンは、数億から数百億のパラメータを持つモデルで、高度な文章生成能力を持っています。

### 2. プロンプト（入力テキスト）

- **プロンプト**: プロンプトは、GPTモデルに対して与えられる入力テキストです。プロンプトはタスクの指示や要求を含むことがあり、モデルがどのような応答を生成するかに影響を与えます。

### 3. タスクと目的

- **タスク**: プロンプトエンジニアリングは、さまざまなタスクや目的に使用できます。例えば、文章の生成、質問応答、文章要約、翻訳、コンテンツ生成、プログラムコードの生成などがあります。

### 4. プロンプトの工夫

- **プロンプトの工夫**: プロンプトの設計は重要で、適切なフォーマットや文脈を持つプロンプトを作成することが、モデルから望ましい応答を得るために必要です。プロンプトエンジニアは、プロンプトを最適化する役割を担います。

### 5. 応用分野

- **応用分野**: プロンプトエンジニアリングは、自動化された文章生成、カスタマーサポート、コンテンツ制作、テキストベースのタスクオートメーションなど、さまざまな分野で応用されています。

### 6. 倫理と注意事項

- **倫理と注意事項**: プロンプトエンジニアリングを使用する際には、倫理的な考慮事項や偽情報の生成に対する注意が必要です。適切なガイドラインと監視が重要です。

プロンプトエンジニアリングは、自然言語処理の進歩において重要な役割を果たし、多くの実用的な応用が期待されています。適切なプロンプトの設計と倫理的な使用が成功の要因となります。

## 概念

**Zero-Shot**：例を提供しない

- Prompt:
   ```
   テキストを中立、否定的、または肯定的に分類してください。

   テキスト: 休暇はまずまずでした。
   所感:
   ```
   
- Output:
   ```
   中立
   ```

**Few-Shot**: 例を提供する

- Prompt:
   ```
   「whatpu」とはタンザニア固有の小さくて毛皮のある動物です。 「whatpu」という言葉を使った文の例は次のとおりです。
   私たちはアフリカを旅行して、これらのとてもかわいいwhatpusを見ました。
   「farduddle」というのは、とても速く上下にジャンプすることを意味します。 「farduddle」という言葉を使用した文の例は次のとおりです。
   ```
   
- Output:
   ```
   私たちは試合に勝ったとき、みんなfarduddleをして祝いました。
   ```

**Chain-of-Thought (CoT)**：推論を提供する

- Prompt:
   ```
   このグループの奇数を合計すると偶数になります。: 17、9、10、12、13、4、2。
   A: 奇数を全て加えると(17, 9, 13)39になります。答えはFalseです。
   このグループの奇数を合計すると偶数になります。: 15、32、5、13、82、7、1。
   A:
   ```
    
- Output:
   ```
   奇数を全て加えると(15, 5, 13, 7, 1)41になります。答えはFalseです。
   ```

**zero-shot CoT**: `Think step by step` を追加する

- Prompt:
   ```
   私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？
   ステップバイステップで考えてみましょう。
   ```
   
- Output:
   ```
   最初に、10個のリンゴから始めました。
   隣人と修理工に合わせて、リンゴを2つずつ渡し、残りは6個になりました。
   次に、5つのリンゴを買い、11個になりました。
   最後に、1つのリンゴを食べたため、残りは10個になります。
   ```

**Self-Consistency (SC)**：生成物を使用する
(誤例)
- Prompt:
   ```
   私が6歳のとき、妹は私の半分の年齢でした。今、私は70歳です。私の妹は何歳ですか？
   ```
   
- Output:
   ```
   35
   ```

- CoT-SC:

**Generated Knowledge Prompting (GKG)**：知識を生成する

- Prompt:
   ```
   入力：ギリシャはメキシコよりも大きい。
   知識：ギリシャは約131,957平方キロメートルであり、メキシコは約1,964,375平方キロメートルであり、メキシコはギリシャよりも1,389％大きい。

   入力：眼鏡は常に曇ります。
   知識：冷たい表面に汗、呼気、および周囲の湿度から水蒸気が着陸し、冷却されて液体の微小な滴に変化して、あなたが霧として見るフィルムを形成すると、眼鏡レンズに結露が生じます。あなたのレンズは、特に外気が寒い場合、あなたの呼気に比べて比較的冷たくなります。

   入力：魚は考えることができる。
   知識：魚は出現よりも知能が高い。記憶などの多くの分野で、魚の認知能力は、非人間の霊長類を含む「より高い」脊椎動物と同等またはそれ以上です。魚の長期記憶は、彼らが複雑な社会的関係を追跡するのを助けます。

   入力：一生にたくさんのタバコを吸うことの共通の影響の1つは、肺がんの発生率が高くなることです。
   知識：生涯にわたり平均して1日に1本未満のタバコを吸った人は、非喫煙者に比べて肺がんで死亡するリスクが9倍高かった。一日あたり1〜10本のタバコを吸った人の中で、肺がんで死亡するリスクは、非喫煙者の約12倍高かった。

   入力：岩と小石は同じ大きさです。
   知識：小石は、堆積学のUdden-Wentworthスケールに基づく4〜64ミリメートルの粒子サイズを持つ岩塊です。小石は、一般的に粒度（直径2〜4ミリメートル）よりも大きく、コブル（直径64〜256ミリメートル）よりも小さいと見なされます。

   入力：ゴルフの一部は、他の人よりも高いポイント総数を得ようとすることです。
   知識：
   ```
   
- Output:
   ```
   ゴルフの目的は、できるだけ少ない打数で一連のホールをプレイすることです。通常、ゴルフのラウンドは18ホールで構成されます。1回のホールは、標準のゴルフコースに1回プレイされます。各打数は1ポイントとしてカウントされ、総打数がゲームの勝者を決定するために使用されます。
   ```

**Tree of Thought (ToT)**： 部分解を「おそらく」に保つ。(BFS/DFSの活用。先読みとバックトラッキング。)

- Prompt:
   ```
   この質問について、3人の異なる専門家が回答していると想像してください。
   すべての専門家は、自分の思考の1つのステップを書き留め、
   それをグループと共有します。
   その後、すべての専門家は次のステップに進みます。以後同様です。
   **もし**専門家の中に、いかなる時点で誤りに気づいた場合は、退場します。
   質問は...
   ```
   
- Output:
   ```
   
   ```

**Retrieval-Augmented Generation (RAG)**：外部の知識ソースにアクセスする

- Prompt:
   ```
   ゴルフの一部は、他の人よりも高いポイント総数を得ようとすることです。「はい」か「いいえ」か？
   ```
   
- Output:
   ```
   はい。
   ```

**Prompt Chaining**：

- Prompt:
   ```
   次の形式で専門記事を作成せよ。

   # -||-
   <p>

   ## -||-
   <p>
   ### -||-
   <p>

   - -||-
   - -||-

   ## -||-
   <p>
   ### -||-
   <p>

   1. -||-
   1. -||-

   ## -||-
   <p>
   ```
   
- Output:
   ```
   
   ```

**Automatic Reasoning and Tool-use (ART)**: A:Select Examples/B:Run Program/C:Fix Mistakes(optional)

- Prompt:
   ```
   Execute code/snippet
   ```
   
- Output:
   ```
   
   ```

**Automatic Prompt Engineer（APE）**： 入力と出力のペアを与えることで，その入力から出力を得るためのプロンプトを自動で生成する

- Prompt:
   ```
   Professor Smith was given the following instructions:<INSERT>
   here are the Professor's response.

   # Demonstration Start
    Input: prove Output disprove
    Input: prove ON OFF
    ...
    # Demonstration End

   write the antonym of the word.
   ```
   
- Output:
   ```
   
   ```

**Active-Prompt**：不確実な推論、選択、注釈付け、推論

- Prompt:
   ```
   
   ```
   
- Output:
   ```
   
   ```

**Directional Stimulus Prompting**： プロンプトに知識を含める

- Prompt:
   ```
   
   ```
   
- Output:
   ```
   
   ```

**Program-Aided Language Models**：プログラムを使用する

- Prompt:
   ```
   question = "Today is 27 February 2023. I was born exactly 25 years ago. What is the date I was born in MM/DD/YYYY?"
   
   DATE_UNDERSTANDING_PROMPT = """..."""
   llm_out = llm(DATE_UNDERSTANDING_PROMPT.format(question=question))
   print(llm_out)

   exec(llm_out)
   print(born)
   ```

- Output:
   ```
   02/27/1998
   ```

**Recursively Criticizes and Improves (RCI)**： 学習させたかのように振る舞わせる

- Prompt:
   ```
   そのエラーメッセージを考慮して、再修正せよ
   ```
   
- Output:
   ```
   
   ```

**ReAct (Reasoning and Acting ~~Retrieval-Augmented Contrastive Training~~ )**：LLMが交互に推論トレースとタスク固有のアクションを生成するフレームワーク


- Prompt:
   ```
   
   ```
   
- Output:
   ```
   
   ```

**Reflexion**：言語的フィードバックを通じて言語ベースのエージェントを強化する


- Prompt:
   ```
   
   ```
   
- Output:
   ```
   
   ```
**Multimodal CoT**：テキストとビジョンを2段階のフレームワーク


- Prompt:
   ```
   
   ```
   
- Output:
   ```
   
   ```

**Graph Prompting**：グラフのための新しいプロンプティングフレームワーク

- Prompt:
   ```
   
   ```
   
- Output:
   ```
   
   ```

**Grounding**：

- Prompt:
   ```
   
   ```
   
- Output:
   ```
   
   ```
