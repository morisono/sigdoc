# 最小二乗法（OLS）

最小二乗法は、データポイントと回帰モデルの間の誤差を最小化することを目的とした統計的な手法です。一般的に、線形回帰モデルに使用されます。以下は最小二乗法の基本的な考え方です。

## 数学的理解

最小二乗法では、以下の式を最小化します：

$$
\min_{\beta} \sum_{i=1}^{n} (y_i - f(x_i))^2
$$

ここで、$y_i$ は実際の観測値、$f(x_i)$ はモデルによる予測値、$\beta$ はモデルのパラメータです。この最小化問題を解くことにより、最適なモデルパラメータが得られます。

## 実践的な知識

最小二乗法の実践において重要な点：

- モデルの選択: データに最適なモデルを選択することが重要です。線形回帰モデル以外にも多くのモデルが存在します。

- パラメータ推定: モデルパラメータの推定には解析的な方法や数値的な最適化手法を使用できます。解析的な方法は、パラメータを閉じた形で求める方法です。

# 最急降下法（Gradient Descent）

最急降下法は、最小化すべき目的関数に対して、その勾配方向にステップを進める反復的な最適化アルゴリズムです。機械学習モデルの学習に広く使用されます。

## 数学的理解

最急降下法の基本的なアイデアは、以下の式で表現されます：

$$
\theta_{k+1} = \theta_k - \alpha \nabla J(\theta_k)
$$

ここで、$\theta$ はモデルパラメータ、$\alpha$ は学習率、$\nabla J(\theta_k)$ は目的関数 $J(\theta)$ の勾配です。

## 実践的な知識

最急降下法の実践において重要な点：

- 学習率の選択: 学習率は収束速度に大きな影響を与えるため、適切な値を選択する必要があります。

- 収束基準: 最急降下法は反復的なアルゴリズムであり、収束基準を設定する必要があります。

- ミニバッチ勾配降下法: 大規模なデータセットの場合、ミニバッチ勾配降下法を使用して効率的に学習できます。

最小二乗法と最急降下法は、異なる用途に使用されるアルゴリズムであり、それぞれの特性と適用例があります。どちらも機械学習の基本的な概念であり、機械学習エンジニアやデータサイエンティストにとって重要なツールです。
